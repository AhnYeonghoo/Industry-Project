{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssrlab/anaconda3/envs/kyuwon_video_swin_transformer/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torchvision.models as models\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "\n",
    "from typing import List, Tuple, Dict\n",
    "import ffmpeg as ff\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gt = pd.read_csv('./dataset/train.csv',encoding='EUC-KR')\n",
    "test_gt = pd.read_csv('./dataset/test.csv', encoding='EUC-KR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>단어_106_가렵다_정면_1_이숙기.MOV</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>단어_108_가슴_정면_1_이숙기.MOV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>단어_113_감전_정면_1_이숙기.MOV</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>단어_120_개_정면_1_이숙기.MOV</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>단어_121_거실_정면_1_이숙기.MOV</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>단어_127_계곡_정면_8.MOV</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>단어_152_기절_정면_8.MOV</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>단어_180_도둑_정면_8.MOV</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>단어_189_동전_정면_8.MOV</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>단어_276_아빠_정면_8.MOV</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       path  label\n",
       "0   단어_106_가렵다_정면_1_이숙기.MOV      0\n",
       "1    단어_108_가슴_정면_1_이숙기.MOV      1\n",
       "2    단어_113_감전_정면_1_이숙기.MOV      2\n",
       "3     단어_120_개_정면_1_이숙기.MOV      3\n",
       "4    단어_121_거실_정면_1_이숙기.MOV      4\n",
       "..                      ...    ...\n",
       "65       단어_127_계곡_정면_8.MOV      5\n",
       "66       단어_152_기절_정면_8.MOV      6\n",
       "67       단어_180_도둑_정면_8.MOV      7\n",
       "68       단어_189_동전_정면_8.MOV      8\n",
       "69       단어_276_아빠_정면_8.MOV      9\n",
       "\n",
       "[70 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>단어_106_가렵다_정면_9.MOV</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>단어_108_가슴_정면_9.MOV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>단어_113_감전_정면_9.MOV</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>단어_120_개_정면_9.MOV</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>단어_121_거실_정면_9.MOV</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>단어_127_계곡_정면_9.MOV</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>단어_152_기절_정면_9.MOV</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>단어_180_도둑_정면_9.MOV</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>단어_189_동전_정면_9.MOV</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>단어_276_아빠_정면_9.MOV</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>단어_106_가렵다_정면_10.MOV</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>단어_108_가슴_정면_10.MOV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>단어_113_감전_정면_10.MOV</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>단어_120_개_정면_10.MOV</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>단어_121_거실_정면_10.MOV</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>단어_127_계곡_정면_10.MOV</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>단어_152_기절_정면_10.MOV</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>단어_180_도둑_정면_10.MOV</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>단어_189_동전_정면_10.MOV</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>단어_276_아빠_정면_10.MOV</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    path  label\n",
       "0    단어_106_가렵다_정면_9.MOV      0\n",
       "1     단어_108_가슴_정면_9.MOV      1\n",
       "2     단어_113_감전_정면_9.MOV      2\n",
       "3      단어_120_개_정면_9.MOV      3\n",
       "4     단어_121_거실_정면_9.MOV      4\n",
       "5     단어_127_계곡_정면_9.MOV      5\n",
       "6     단어_152_기절_정면_9.MOV      6\n",
       "7     단어_180_도둑_정면_9.MOV      7\n",
       "8     단어_189_동전_정면_9.MOV      8\n",
       "9     단어_276_아빠_정면_9.MOV      9\n",
       "10  단어_106_가렵다_정면_10.MOV      0\n",
       "11   단어_108_가슴_정면_10.MOV      1\n",
       "12   단어_113_감전_정면_10.MOV      2\n",
       "13    단어_120_개_정면_10.MOV      3\n",
       "14   단어_121_거실_정면_10.MOV      4\n",
       "15   단어_127_계곡_정면_10.MOV      5\n",
       "16   단어_152_기절_정면_10.MOV      6\n",
       "17   단어_180_도둑_정면_10.MOV      7\n",
       "18   단어_189_동전_정면_10.MOV      8\n",
       "19   단어_276_아빠_정면_10.MOV      9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 각 영상마다 frame, width, height 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_preprocessing_input(file_path: str, file_name: str, dictionary: Dict[str, str], training: bool = True) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    probe = ff.probe(filePath)\n",
    "    video_streams = [stream for stream in probe[\"streams\"] if stream[\"codec_type\"] == \"video\"]\n",
    "    print('frame = ', video_streams[0]['nb_frames'], 'width = ', video_streams[0]['coded_width'], ', height = ',video_streams[0]['coded_height'])\n",
    "    del probe\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset/TRAIN/단어_106_가렵다_정면_1_이숙기.MOV\n",
      "frame =  190 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_113_감전_정면_8.MOV\n",
      "frame =  332 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_108_가슴_정면_6.MOV\n",
      "frame =  205 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_180_도둑_정면_1_이숙기.MOV\n",
      "frame =  180 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_108_가슴_정면_1_이숙기.MOV\n",
      "frame =  177 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_180_도둑_정면_8.MOV\n",
      "frame =  329 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_127_계곡_정면_1_이숙기.MOV\n",
      "frame =  184 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_120_개_정면_4.MOV\n",
      "frame =  172 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_108_가슴_정면_3.MOV\n",
      "frame =  343 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_113_감전_정면_6.MOV\n",
      "frame =  228 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_152_기절_정면_4.MOV\n",
      "frame =  183 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_127_계곡_정면_6.MOV\n",
      "frame =  236 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_120_개_정면_7.MOV\n",
      "frame =  221 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_108_가슴_정면_7.MOV\n",
      "frame =  247 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_106_가렵다_정면_6.MOV\n",
      "frame =  200 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_180_도둑_정면_6.MOV\n",
      "frame =  213 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_189_동전_정면_1_이숙기.MOV\n",
      "frame =  183 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_108_가슴_정면_4.MOV\n",
      "frame =  180 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_189_동전_정면_3.MOV\n",
      "frame =  391 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_121_거실_정면_6.MOV\n",
      "frame =  204 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_276_아빠_정면_7.MOV\n",
      "frame =  223 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_106_가렵다_정면_8.MOV\n",
      "frame =  293 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_127_계곡_정면_7.MOV\n",
      "frame =  245 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_113_감전_정면_3.MOV\n",
      "frame =  356 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_152_기절_정면_7.MOV\n",
      "frame =  248 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_121_거실_정면_7.MOV\n",
      "frame =  235 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_152_기절_정면_1_이숙기.MOV\n",
      "frame =  188 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_127_계곡_정면_4.MOV\n",
      "frame =  176 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_106_가렵다_정면_3.MOV\n",
      "frame =  503 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_113_감전_정면_4.MOV\n",
      "frame =  160 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_127_계곡_정면_8.MOV\n",
      "frame =  344 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_276_아빠_정면_3.MOV\n",
      "frame =  383 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_121_거실_정면_3.MOV\n",
      "frame =  308 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_120_개_정면_1_이숙기.MOV\n",
      "frame =  171 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_180_도둑_정면_3.MOV\n",
      "frame =  356 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_106_가렵다_정면_4.MOV\n",
      "frame =  170 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_276_아빠_정면_8.MOV\n",
      "frame =  295 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_152_기절_정면_8.MOV\n",
      "frame =  337 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_152_기절_정면_3.MOV\n",
      "frame =  352 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_120_개_정면_3.MOV\n",
      "frame =  376 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_120_개_정면_6.MOV\n",
      "frame =  227 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_113_감전_정면_7.MOV\n",
      "frame =  223 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_180_도둑_정면_7.MOV\n",
      "frame =  200 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_127_계곡_정면_3.MOV\n",
      "frame =  350 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_180_도둑_정면_4.MOV\n",
      "frame =  181 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_152_기절_정면_6.MOV\n",
      "frame =  227 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_121_거실_정면_8.MOV\n",
      "frame =  312 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_189_동전_정면_7.MOV\n",
      "frame =  235 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_121_거실_정면_1_이숙기.MOV\n",
      "frame =  179 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_120_개_정면_8.MOV\n",
      "frame =  327 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_276_아빠_정면_6.MOV\n",
      "frame =  211 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_189_동전_정면_8.MOV\n",
      "frame =  338 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_121_거실_정면_4.MOV\n",
      "frame =  172 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_276_아빠_정면_4.MOV\n",
      "frame =  168 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_189_동전_정면_6.MOV\n",
      "frame =  220 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_276_아빠_정면_1_이숙기.MOV\n",
      "frame =  173 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_108_가슴_정면_8.MOV\n",
      "frame =  304 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_189_동전_정면_4.MOV\n",
      "frame =  186 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_113_감전_정면_1_이숙기.MOV\n",
      "frame =  172 width =  1920 , height =  1088\n",
      "./dataset/TRAIN/단어_106_가렵다_정면_7.MOV\n",
      "frame =  251 width =  1920 , height =  1088\n"
     ]
    }
   ],
   "source": [
    "# training_set_data = []\n",
    "\n",
    "path = './dataset/TRAIN'\n",
    "for filename in os.listdir(path):\n",
    "    filePath = path+'/'+filename\n",
    "    print(filePath)\n",
    "    check_preprocessing_input(file_path = filePath, file_name = filename, dictionary = train_gt)\n",
    "    # training_set_data.append(preprocessing_input(file_path= filePath, file_name= filename, dictionary= gt, training= True))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추출 전략\n",
    "\n",
    "##### 모든 영상에서 각각 30프레임씩 추출\n",
    " - (frame/30) 프레임 만큼 이동하면서 프레임 추출\n",
    " - width, height은 (224,224)로 resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_frames(file_path: str) -> int:\n",
    "    probe = ff.probe(filePath)\n",
    "    video_streams = [stream for stream in probe[\"streams\"] if stream[\"codec_type\"] == \"video\"]\n",
    "    #width = video_streams[0]['coded_width']\n",
    "    #height = video_streams[0]['coded_height']\n",
    "    del probe\n",
    "    return video_streams[0]['nb_frames']\n",
    "\n",
    "def extract_N_video_frames(file_path: str, number_of_samples: int = 6) -> List[np.ndarray]:\n",
    "    nb_frames = int(get_number_of_frames(file_path= filePath))\n",
    "    \n",
    "    div = 30\n",
    "    div_frames = nb_frames / div\n",
    "    temp = 0\n",
    "    video_frames = []\n",
    "    print('이번 영상은')\n",
    "    cap = cv2.VideoCapture(filePath)\n",
    "    for ind in range(30):\n",
    "        cap.set(1,int(temp))\n",
    "        temp += div_frames\n",
    "        res, frame = cap.read()\n",
    "        video_frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    cap.release()\n",
    "    print('개수 = ', len(video_frames))\n",
    "    del cap\n",
    "    return video_frames\n",
    "\n",
    "def resize_image(image: np.ndarray, new_size: Tuple[int,int]) -> np.ndarray:\n",
    "    return cv2.resize(image, new_size, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "def preprocessing_input(file_path: str, file_name: str, gt = train_gt, training: bool = True) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    sampled = extract_N_video_frames(file_path= filePath, number_of_samples= 6)\n",
    "    resized_images = [resize_image(image= im, new_size= (224,224)) for im in sampled]\n",
    "    preprocessed_video = np.stack(resized_images)\n",
    "    if sampled == None:\n",
    "        print(file_name)\n",
    "    for i in range(len(gt)):\n",
    "        if gt.loc[i,'path'] == file_name:\n",
    "            video_gt = gt.loc[i,'label']\n",
    "    return (preprocessed_video, video_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이번 영상은\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "개수 =  30\n",
      "1\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "2\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "3\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "4\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "5\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "6\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "7\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "8\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "9\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "10\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "11\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "12\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "13\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "14\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "15\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "16\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "17\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "18\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "19\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "20\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "21\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "22\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "23\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "24\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "25\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "26\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "27\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "28\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "29\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "30\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "31\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "32\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "33\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "34\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "35\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "36\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "37\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "38\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "39\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "40\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "41\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "42\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "43\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "44\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "45\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "46\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "47\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "48\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "49\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "50\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "51\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "52\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "53\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "54\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "55\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "56\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "57\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "58\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "59\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "training_set_data = []\n",
    "\n",
    "path = './dataset/TRAIN'\n",
    "i=1\n",
    "for filename in os.listdir(path):\n",
    "    filePath = path+'/'+filename\n",
    "    training_set_data.append(preprocessing_input(file_path= filePath, file_name= filename, gt= train_gt, training= True))\n",
    "    print(i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_to_expected_input(dataset: List[Tuple[np.ndarray, np.ndarray]]) -> Tuple[np.ndarray,np.ndarray]:\n",
    "    \n",
    "    x0_list = []\n",
    "    y_list = []\n",
    "    for i in range(0,len(dataset)):\n",
    "        x0_list.append(dataset[i][0])\n",
    "        y_list.append(dataset[i][1])\n",
    "    return (np.stack(x0_list),np.stack(y_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = reshape_to_expected_input(dataset= training_set_data)\n",
    "del training_set_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = 'training_set.dat'\n",
    "with open(savename, \"wb\") as f:\n",
    "    pickle.dump(train_input, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이번 영상은\n",
      "개수 =  30\n",
      "0\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "1\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "2\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "3\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "4\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "5\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "6\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "7\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "8\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "9\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "10\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "11\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "12\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "13\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "14\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "15\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "16\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "17\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "18\n",
      "이번 영상은\n",
      "개수 =  30\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "test_set_data = []\n",
    "\n",
    "path = './dataset/TEST'\n",
    "i=0\n",
    "for filename in os.listdir(path):\n",
    "    filePath = path+'/'+filename\n",
    "    test_set_data.append(preprocessing_input(file_path= filePath, file_name= filename, gt= test_gt, training= False))\n",
    "    print(i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = reshape_to_expected_input(dataset= test_set_data)\n",
    "del test_set_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = 'test_set.dat'\n",
    "with open(savename, \"wb\") as f:\n",
    "    pickle.dump(test_input, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# csv 파일 인코딩 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "\n",
    "with open('/home/ssrlab/kw/개인/Industry-Project/ai/dataset/train.csv', 'rb') as rawdata:\n",
    "    result = chardet.detect(rawdata.read(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'EUC-KR', 'confidence': 0.99, 'language': 'Korean'}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kyuwon_video_swin_transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
